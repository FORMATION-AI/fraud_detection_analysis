{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2284dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Face Enrollment Prototype (MVP)\n",
    "# End-to-end enrollment pipeline for step-up authentication.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Face Enrollment Prototype (MVP)\n",
    "# - Accept 1–3 images for a user\n",
    "# - Detect exactly 1 face per image\n",
    "# - Align + embed (ArcFace via InsightFace)\n",
    "# - Compute quality metrics\n",
    "# - Store: individual embeddings + mean template\n",
    "# - Simulate persistence (dict / parquet), later pgvector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have the dependencies installed, run:\n",
    "```\n",
    "%pip install -q insightface onnxruntime opencv-python numpy pandas pydantic matplotlib pyarrow\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f7a871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q insightface onnxruntime opencv-python numpy pandas pydantic matplotlib pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fdbc9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Imports: standard libs, CV utilities, and InsightFace\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from insightface.app import FaceAnalysis    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5c65d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT: C:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\n",
      "DATA_DIR exists: True C:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\data\n",
      "ENROLLMENT_SAMPLES_DIR exists: True C:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\data\\enrollment_samples\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Resolve repo root and local enrollment data directory\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    \"\"\"\n",
    "    Walk upward until we find a marker file that indicates the repo root.\n",
    "    Works even if the notebook lives in nested folders like notebooks/notebooks/.\n",
    "    \"\"\"\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    markers = [\"pyproject.toml\", \".git\"]  # pick what exists in your repo\n",
    "    for _ in range(15):  # avoid infinite loops\n",
    "        if any((p / m).exists() for m in markers):\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(\"Could not locate repo root (pyproject.toml or .git not found).\")\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "DATA_DIR = REPO_ROOT / \"data\"\n",
    "ENROLLMENT_SAMPLES_DIR = DATA_DIR / \"enrollment_samples\"\n",
    "print(\"DATA_DIR exists:\", DATA_DIR.exists(), DATA_DIR)\n",
    "print(\"ENROLLMENT_SAMPLES_DIR exists:\", ENROLLMENT_SAMPLES_DIR.exists(), ENROLLMENT_SAMPLES_DIR)\n",
    "\n",
    "if not ENROLLMENT_SAMPLES_DIR.exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing local enrollment samples. Expected: <repo>/data/enrollment_samples\"\n",
    "    )\n",
    "import sys\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a983a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Global configuration and quality thresholds\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "MODEL_PACK = \"buffalo_l\"   # includes detection + recognition\n",
    "MODEL_NAME = \"arcface\"     # logical name you store\n",
    "MODEL_VERSION = \"buffalo_l@insightface\"  # store something stable\n",
    "\n",
    "MAX_IMAGES = 3\n",
    "MIN_IMAGES = 1\n",
    "\n",
    "MIN_FACE_WIDTH_PX = 90\n",
    "MIN_DET_SCORE = 0.5             # detection confidence threshold\n",
    "MAX_YAW_ABS = 30                 # optional; degrees (if you compute pose)\n",
    "MAX_PITCH_ABS = 20               # optional\n",
    "\n",
    "# Quality thresholds (tune later via plots)\n",
    "BLUR_MIN_LAPLACIAN_VAR = 8.0\n",
    "BRIGHTNESS_MIN = 25\n",
    "BRIGHTNESS_MAX = 235\n",
    "MIN_FACE_AREA_RATIO = 0.02      # bbox area / image area\n",
    "\n",
    "OUTPUT_DIR = Path(\"../artifacts/face_enrollment\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ed32bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\.venv311\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\l/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\l/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\l/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\l/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\l/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "Loaded: buffalo_l\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Initialize InsightFace FaceAnalysis (CPU)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "app = FaceAnalysis(name=MODEL_PACK)\n",
    "# ctx_id=0 uses GPU if available; -1 forces CPU\n",
    "app.prepare(ctx_id=-1, det_size=(640, 640))\n",
    "\n",
    "print(\"Loaded:\", MODEL_PACK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9f8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Image loading utilities\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def load_image_bgr(path: str | Path) -> np.ndarray:\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not read image: {path}\")\n",
    "    return img\n",
    "\n",
    "def list_images(folder: str | Path) -> List[Path]:\n",
    "    folder = Path(folder)\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\"}\n",
    "    return [p for p in sorted(folder.iterdir()) if p.suffix.lower() in exts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a260dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4af075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.face.quality import (\n",
    "    blur_laplacian_var,\n",
    "    brightness_mean,\n",
    "    face_area_ratio,\n",
    "    bbox_width,\n",
    "    quality_checks,\n",
    "    passes_quality,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf984ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Face detection and validation gates\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class EnrollmentError(Exception):\n",
    "    pass\n",
    "\n",
    "def detect_one_face(bgr: np.ndarray):\n",
    "    faces = app.get(bgr)\n",
    "    if len(faces) != 1:\n",
    "        raise EnrollmentError(f\"Expected exactly 1 face, got {len(faces)}\")\n",
    "    face = faces[0]\n",
    "\n",
    "    # detection score and bbox checks\n",
    "    if getattr(face, \"det_score\", 1.0) < MIN_DET_SCORE:\n",
    "        raise EnrollmentError(f\"Detection score too low: {face.det_score:.3f}\")\n",
    "\n",
    "    bw = bbox_width(face.bbox)\n",
    "    if bw < MIN_FACE_WIDTH_PX:\n",
    "        raise EnrollmentError(f\"Face too small: bbox_width={bw:.1f}px\")\n",
    "\n",
    "    return face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab525f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c03f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Embedding extraction and normalization\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def l2_normalize(x: np.ndarray) -> np.ndarray:\n",
    "    x = x.astype(np.float32)\n",
    "    n = np.linalg.norm(x) + 1e-12\n",
    "    return x / n\n",
    "\n",
    "def extract_embedding(face) -> np.ndarray:\n",
    "    # InsightFace typically returns L2-normalized already, but normalize anyway.\n",
    "    emb = np.asarray(face.embedding, dtype=np.float32)\n",
    "    return l2_normalize(emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb648b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2129c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality evaluation now imported from src.face.quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642c3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Template record schema (mirrors pgvector persistence)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class TemplateRecord:\n",
    "    template_id: str\n",
    "    user_id: str\n",
    "    embedding: np.ndarray\n",
    "    is_mean_template: bool\n",
    "    model_name: str\n",
    "    model_version: str\n",
    "    quality: Dict[str, Any]\n",
    "    created_at: str\n",
    "\n",
    "def now_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517d91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f64a617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Enrollment pipeline (core logic)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def enroll_user_from_images(user_id: str, image_paths: List[Path]) -> Dict[str, Any]:\n",
    "    if not (MIN_IMAGES <= len(image_paths) <= MAX_IMAGES):\n",
    "        raise EnrollmentError(f\"Need {MIN_IMAGES}–{MAX_IMAGES} images, got {len(image_paths)}\")\n",
    "\n",
    "    template_records: List[TemplateRecord] = []\n",
    "    embeddings: List[np.ndarray] = []\n",
    "    per_image_quality: List[Dict[str, Any]] = []\n",
    "\n",
    "    for p in image_paths:\n",
    "        bgr = load_image_bgr(p)\n",
    "\n",
    "        face = detect_one_face(bgr)\n",
    "        q = quality_checks(bgr, face.bbox)\n",
    "        ok, reasons = passes_quality(\n",
    "    q,\n",
    "    blur_min_laplacian_var=BLUR_MIN_LAPLACIAN_VAR,\n",
    "    brightness_min=BRIGHTNESS_MIN,\n",
    "    brightness_max=BRIGHTNESS_MAX,\n",
    "    min_face_area_ratio=MIN_FACE_AREA_RATIO,\n",
    ")\n",
    "        q[\"quality_ok\"] = ok\n",
    "        q[\"reject_reasons\"] = reasons\n",
    "        q[\"det_score\"] = float(getattr(face, \"det_score\", 1.0))\n",
    "\n",
    "        if not ok:\n",
    "            raise EnrollmentError(\n",
    "    f\"Quality reject for {p.name}: {reasons} | \"\n",
    "    f\"blur={q['blur_laplacian_var']:.1f}, \"\n",
    "    f\"bright={q['brightness_mean']:.1f}, \"\n",
    "    f\"ratio={q['face_area_ratio']:.3f}, \"\n",
    "    f\"bbox_w={q['bbox_width_px']:.1f}, \"\n",
    "    f\"det={q['det_score']:.3f}\"\n",
    ")\n",
    "\n",
    "\n",
    "        emb = extract_embedding(face)\n",
    "\n",
    "        template_id = str(uuid.uuid4())\n",
    "        template_records.append(\n",
    "            TemplateRecord(\n",
    "                template_id=template_id,\n",
    "                user_id=user_id,\n",
    "                embedding=emb,\n",
    "                is_mean_template=False,\n",
    "                model_name=MODEL_NAME,\n",
    "                model_version=MODEL_VERSION,\n",
    "                quality=q,\n",
    "                created_at=now_iso(),\n",
    "            )\n",
    "        )\n",
    "        embeddings.append(emb)\n",
    "        per_image_quality.append(q)\n",
    "\n",
    "    # mean template\n",
    "    mean_emb = l2_normalize(np.mean(np.stack(embeddings, axis=0), axis=0))\n",
    "    template_records.append(\n",
    "        TemplateRecord(\n",
    "            template_id=str(uuid.uuid4()),\n",
    "            user_id=user_id,\n",
    "            embedding=mean_emb,\n",
    "            is_mean_template=True,\n",
    "            model_name=MODEL_NAME,\n",
    "            model_version=MODEL_VERSION,\n",
    "            quality={\"note\": \"mean_template_from_individuals\", \"num_sources\": len(embeddings)},\n",
    "            created_at=now_iso(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    response = {\n",
    "        \"user_id\": user_id,\n",
    "        \"enrolled\": True,\n",
    "        \"num_templates\": len(template_records),\n",
    "        \"num_individual_templates\": len(embeddings),\n",
    "        \"stored_mean_template\": True,\n",
    "        \"model\": MODEL_VERSION,\n",
    "        \"templates\": template_records,\n",
    "        \"per_image_quality\": per_image_quality,\n",
    "    }\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88ebc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\.venv311\\Lib\\site-packages\\insightface\\utils\\face_align.py:23: FutureWarning: `estimate` is deprecated since version 0.26 and will be removed in version 2.2. Please use `SimilarityTransform.from_estimate` class constructor instead.\n",
      "  tform.estimate(lmk, dst)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>num_faces</th>\n",
       "      <th>blur_laplacian_var</th>\n",
       "      <th>brightness_mean</th>\n",
       "      <th>face_area_ratio</th>\n",
       "      <th>bbox_width_px</th>\n",
       "      <th>det_score</th>\n",
       "      <th>quality_ok</th>\n",
       "      <th>reject_reasons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIN_20260206_12_45_37_Pro.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>8.081144</td>\n",
       "      <td>129.144322</td>\n",
       "      <td>0.143248</td>\n",
       "      <td>304.177094</td>\n",
       "      <td>0.784642</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIN_20260206_12_45_41_Pro.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>13.732615</td>\n",
       "      <td>128.239375</td>\n",
       "      <td>0.135392</td>\n",
       "      <td>294.337402</td>\n",
       "      <td>0.715901</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WIN_20260206_12_45_44_Pro.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>15.078793</td>\n",
       "      <td>127.877875</td>\n",
       "      <td>0.137489</td>\n",
       "      <td>295.608765</td>\n",
       "      <td>0.738799</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file  num_faces  blur_laplacian_var  \\\n",
       "0  WIN_20260206_12_45_37_Pro.jpg          1            8.081144   \n",
       "1  WIN_20260206_12_45_41_Pro.jpg          1           13.732615   \n",
       "2  WIN_20260206_12_45_44_Pro.jpg          1           15.078793   \n",
       "\n",
       "   brightness_mean  face_area_ratio  bbox_width_px  det_score  quality_ok  \\\n",
       "0       129.144322         0.143248     304.177094   0.784642        True   \n",
       "1       128.239375         0.135392     294.337402   0.715901        True   \n",
       "2       127.877875         0.137489     295.608765   0.738799        True   \n",
       "\n",
       "  reject_reasons  \n",
       "0                 \n",
       "1                 \n",
       "2                 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Quality scan of sample images (pre-enrollment)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "user_id = \"user_123\"\n",
    "img_dir = ENROLLMENT_SAMPLES_DIR / user_id\n",
    "paths = list_images(img_dir)[:3]\n",
    "\n",
    "rows = []\n",
    "for p in paths:\n",
    "    bgr = load_image_bgr(p)\n",
    "    faces = app.get(bgr)\n",
    "\n",
    "    row = {\"file\": p.name, \"num_faces\": len(faces)}\n",
    "    if len(faces) == 1:\n",
    "        face = faces[0]\n",
    "        q = quality_checks(bgr, face.bbox)\n",
    "        q[\"det_score\"] = float(getattr(face, \"det_score\", 1.0))\n",
    "        ok, reasons = passes_quality(\n",
    "    q,\n",
    "    blur_min_laplacian_var=BLUR_MIN_LAPLACIAN_VAR,\n",
    "    brightness_min=BRIGHTNESS_MIN,\n",
    "    brightness_max=BRIGHTNESS_MAX,\n",
    "    min_face_area_ratio=MIN_FACE_AREA_RATIO,\n",
    ")\n",
    "        row.update(q)\n",
    "        row[\"quality_ok\"] = ok\n",
    "        row[\"reject_reasons\"] = \",\".join(reasons)\n",
    "    rows.append(row)\n",
    "\n",
    "dfq = pd.DataFrame(rows)\n",
    "dfq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03db988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_dir: C:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\data\\enrollment_samples\\user_123 exists: True\n",
      "found images: 3 ['WIN_20260206_12_45_37_Pro.jpg', 'WIN_20260206_12_45_41_Pro.jpg', 'WIN_20260206_12_45_44_Pro.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\l\\Documents\\Formation\\fraud_detection_analysis\\.venv311\\Lib\\site-packages\\insightface\\utils\\face_align.py:23: FutureWarning: `estimate` is deprecated since version 0.26 and will be removed in version 2.2. Please use `SimilarityTransform.from_estimate` class constructor instead.\n",
      "  tform.estimate(lmk, dst)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 'user_123', 'enrolled': True, 'num_templates': 4, 'model': 'buffalo_l@insightface'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Run enrollment on a sample user\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "user_id = \"user_123\"\n",
    "img_dir = ENROLLMENT_SAMPLES_DIR / user_id\n",
    "\n",
    "print(\"img_dir:\", img_dir, \"exists:\", img_dir.exists())\n",
    "paths = list_images(img_dir)[:3]\n",
    "print(\"found images:\", len(paths), [p.name for p in paths])\n",
    "\n",
    "result = enroll_user_from_images(user_id=user_id, image_paths=paths)\n",
    "print({\n",
    "    \"user_id\": result[\"user_id\"],\n",
    "    \"enrolled\": result[\"enrolled\"],\n",
    "    \"num_templates\": result[\"num_templates\"],\n",
    "    \"model\": result[\"model\"],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7073607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>template_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mean_template</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_version</th>\n",
       "      <th>created_at</th>\n",
       "      <th>quality_json</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b428b79f-fe4c-495f-b44c-692eee335cc8</td>\n",
       "      <td>user_123</td>\n",
       "      <td>False</td>\n",
       "      <td>arcface</td>\n",
       "      <td>buffalo_l@insightface</td>\n",
       "      <td>2026-02-06T13:28:00.942324+00:00</td>\n",
       "      <td>{\"blur_laplacian_var\": 8.081144086668226, \"bri...</td>\n",
       "      <td>[0.04680231213569641, 0.028721217066049576, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27749dca-7b88-46cc-83e3-761f68cc5c01</td>\n",
       "      <td>user_123</td>\n",
       "      <td>False</td>\n",
       "      <td>arcface</td>\n",
       "      <td>buffalo_l@insightface</td>\n",
       "      <td>2026-02-06T13:28:01.564490+00:00</td>\n",
       "      <td>{\"blur_laplacian_var\": 13.732615009825905, \"br...</td>\n",
       "      <td>[0.03495236113667488, 0.02492390014231205, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36771bb7-57be-415f-a63c-0de0a7a89419</td>\n",
       "      <td>user_123</td>\n",
       "      <td>False</td>\n",
       "      <td>arcface</td>\n",
       "      <td>buffalo_l@insightface</td>\n",
       "      <td>2026-02-06T13:28:02.174828+00:00</td>\n",
       "      <td>{\"blur_laplacian_var\": 15.078793401251898, \"br...</td>\n",
       "      <td>[0.024583136662840843, 0.029344934970140457, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66acbd57-97f7-4d40-82b8-8113d5dd50f1</td>\n",
       "      <td>user_123</td>\n",
       "      <td>True</td>\n",
       "      <td>arcface</td>\n",
       "      <td>buffalo_l@insightface</td>\n",
       "      <td>2026-02-06T13:28:02.175354+00:00</td>\n",
       "      <td>{\"note\": \"mean_template_from_individuals\", \"nu...</td>\n",
       "      <td>[0.03625284880399704, 0.028293095529079437, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            template_id   user_id  is_mean_template  \\\n",
       "0  b428b79f-fe4c-495f-b44c-692eee335cc8  user_123             False   \n",
       "1  27749dca-7b88-46cc-83e3-761f68cc5c01  user_123             False   \n",
       "2  36771bb7-57be-415f-a63c-0de0a7a89419  user_123             False   \n",
       "3  66acbd57-97f7-4d40-82b8-8113d5dd50f1  user_123              True   \n",
       "\n",
       "  model_name          model_version                        created_at  \\\n",
       "0    arcface  buffalo_l@insightface  2026-02-06T13:28:00.942324+00:00   \n",
       "1    arcface  buffalo_l@insightface  2026-02-06T13:28:01.564490+00:00   \n",
       "2    arcface  buffalo_l@insightface  2026-02-06T13:28:02.174828+00:00   \n",
       "3    arcface  buffalo_l@insightface  2026-02-06T13:28:02.175354+00:00   \n",
       "\n",
       "                                        quality_json  \\\n",
       "0  {\"blur_laplacian_var\": 8.081144086668226, \"bri...   \n",
       "1  {\"blur_laplacian_var\": 13.732615009825905, \"br...   \n",
       "2  {\"blur_laplacian_var\": 15.078793401251898, \"br...   \n",
       "3  {\"note\": \"mean_template_from_individuals\", \"nu...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.04680231213569641, 0.028721217066049576, 0....  \n",
       "1  [0.03495236113667488, 0.02492390014231205, 0.0...  \n",
       "2  [0.024583136662840843, 0.029344934970140457, 0...  \n",
       "3  [0.03625284880399704, 0.028293095529079437, 0....  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Convert templates to tabular form\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def template_to_row(t: TemplateRecord) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"template_id\": t.template_id,\n",
    "        \"user_id\": t.user_id,\n",
    "        \"is_mean_template\": t.is_mean_template,\n",
    "        \"model_name\": t.model_name,\n",
    "        \"model_version\": t.model_version,\n",
    "        \"created_at\": t.created_at,\n",
    "        \"quality_json\": json.dumps(t.quality),\n",
    "        \"embedding\": t.embedding.tolist(),   # for notebook artifact; pgvector will store vector directly\n",
    "    }\n",
    "\n",
    "rows = [template_to_row(t) for t in result[\"templates\"]]\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e84de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\artifacts\\face_enrollment\\enrollment_user_123.json\n",
      "Saved: ..\\artifacts\\face_enrollment\\enrollment_user_123.parquet\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Persist enrollment artifacts (JSON + Parquet)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "out_json = OUTPUT_DIR / f\"enrollment_{result['user_id']}.json\"\n",
    "out_parquet = OUTPUT_DIR / f\"enrollment_{result['user_id']}.parquet\"\n",
    "\n",
    "with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"user_id\": result[\"user_id\"],\n",
    "        \"model\": result[\"model\"],\n",
    "        \"num_templates\": result[\"num_templates\"],\n",
    "        \"templates\": rows,\n",
    "    }, f, indent=2)\n",
    "\n",
    "df.to_parquet(out_parquet, index=False)\n",
    "\n",
    "print(\"Saved:\", out_json)\n",
    "print(\"Saved:\", out_parquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506cce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d93abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16081269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861533f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29450b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94bee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5de2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e532b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d63caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e53ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e33b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31540f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2010e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f34ed34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de1183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfc8b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f909155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Experiments (Genuine vs Impostor)\n",
    "We use L2-normalized embeddings. Dot product equals cosine similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "# Collect embeddings per user from enrollment_samples\n",
    "user_embeddings: dict[str, list[np.ndarray]] = defaultdict(list)\n",
    "failures: list[str] = []\n",
    "\n",
    "for user_dir in sorted([d for d in ENROLLMENT_SAMPLES_DIR.iterdir() if d.is_dir()]):\n",
    "    user_id = user_dir.name\n",
    "    paths = list_images(user_dir)[:MAX_IMAGES]\n",
    "    for p in paths:\n",
    "        try:\n",
    "            bgr = load_image_bgr(p)\n",
    "            face = detect_one_face(bgr)\n",
    "            q = quality_checks(bgr, face.bbox)\n",
    "            ok, reasons = passes_quality(q)\n",
    "            if not ok:\n",
    "                failures.append(f\"{user_id}/{p.name}: {reasons}\")\n",
    "                continue\n",
    "            emb = extract_embedding(face)\n",
    "            user_embeddings[user_id].append(emb)\n",
    "        except Exception as e:\n",
    "            failures.append(f\"{user_id}/{p.name}: {e}\")\n",
    "\n",
    "print(\"users with embeddings:\", {k: len(v) for k, v in user_embeddings.items()})\n",
    "print(\"failures:\", len(failures))\n",
    "\n",
    "# Genuine scores (within same user)\n",
    "genuine_scores: list[float] = []\n",
    "for user_id, embs in user_embeddings.items():\n",
    "    if len(embs) >= 2:\n",
    "        for a, b in itertools.combinations(embs, 2):\n",
    "            genuine_scores.append(float(np.dot(a, b)))\n",
    "\n",
    "# Impostor scores (between users, compare mean templates)\n",
    "user_means = {\n",
    "    u: l2_normalize(np.mean(np.stack(embs, axis=0), axis=0))\n",
    "    for u, embs in user_embeddings.items() if len(embs) >= 1\n",
    "}\n",
    "\n",
    "impostor_scores: list[float] = []\n",
    "for (u1, e1), (u2, e2) in itertools.combinations(user_means.items(), 2):\n",
    "    impostor_scores.append(float(np.dot(e1, e2)))\n",
    "\n",
    "print(f\"genuine_scores: {len(genuine_scores)}, impostor_scores: {len(impostor_scores)}\")\n",
    "\n",
    "# Plot distributions (if available)\n",
    "if genuine_scores or impostor_scores:\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    if genuine_scores:\n",
    "        plt.hist(genuine_scores, bins=20, alpha=0.7, label=\"genuine\")\n",
    "    if impostor_scores:\n",
    "        plt.hist(impostor_scores, bins=20, alpha=0.7, label=\"impostor\")\n",
    "    plt.xlabel(\"cosine similarity (dot product)\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Genuine vs Impostor Score Distributions\")\n",
    "    plt.show()\n",
    "\n",
    "# Propose thresholds\n",
    "if genuine_scores and impostor_scores:\n",
    "    T_low = float(np.percentile(impostor_scores, 99))   # fail below this\n",
    "    T_high = float(np.percentile(genuine_scores, 10))   # pass above this\n",
    "    if T_low > T_high:\n",
    "        mid = (T_low + T_high) / 2.0\n",
    "        T_low = mid - 0.02\n",
    "        T_high = mid + 0.02\n",
    "    print({\"T_low\": round(T_low, 4), \"T_high\": round(T_high, 4)})\n",
    "else:\n",
    "    print(\"Not enough data to propose thresholds. Add >=2 users and >=2 images per user.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud (py311)",
   "language": "python",
   "name": "fraud-venv311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}